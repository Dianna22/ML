{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocessing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "q_4gpavVHicr",
        "IvNhwSA6sCmW",
        "0NIvfOtVWmfN",
        "63Qtnys6HHWK",
        "VcHWrShBGyJm",
        "qritQrBHNpY_",
        "IbW95n6SNtSn",
        "cx1H9gMUKetB"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dianna22/ML/blob/master/SocialMediaBUZZ/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KxoGyvhx3x33",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import normalize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "adhHYwlXrncS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, auc, accuracy_score, confusion_matrix, precision_score, balanced_accuracy_score, recall_score, roc_auc_score\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sOdwARku4G65",
        "colab_type": "code",
        "outputId": "44690e22-2ec0-4a53-b690-164a8eeb333f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NK1_rUue4HFF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH_PREFIX = '/content/gdrive/My Drive/ML/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RvTcd_E1HdFj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Load datasets"
      ]
    },
    {
      "metadata": {
        "id": "ABQnKUUm8FEf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TWITTER_RELATIVE_500 = PATH_PREFIX + \"data/Twitter-Relative-Sigma-500.data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HfzAQnjb3x1f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TWITTER_TRAIN = PATH_PREFIX + \"data/train_500\"\n",
        "TWITTER_TEST = PATH_PREFIX + \"data/test_500\"\n",
        "TWITTER_VAL = PATH_PREFIX + \"data/val_500\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JTbSn-Qu3xzH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_dataset(path):\n",
        "\tdata = pd.read_csv(path)\n",
        "\treturn data[data.columns[:-1]], data[data.columns[-1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CiQIJkim8FyX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_X, data_Y = load_dataset(TWITTER_RELATIVE_500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uTfiex223xwz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, Y_train = load_dataset(TWITTER_TRAIN)\n",
        "X_val, Y_val = load_dataset(TWITTER_VAL)\n",
        "X_test, Y_test = load_dataset(TWITTER_TEST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Zl6Yb_L3xua",
        "colab_type": "code",
        "outputId": "cc68fc2c-99bb-4afb-fddb-047e76a7a5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "print(Y_train.value_counts()[0]/Y_train.value_counts()[1])\n",
        "print(Y_val.value_counts()[0]/Y_val.value_counts()[1])\n",
        "print(Y_test.value_counts()[0]/Y_test.value_counts()[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37.076955602537\n",
            "38.15304347826087\n",
            "40.38529411764706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q_4gpavVHicr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Normalization"
      ]
    },
    {
      "metadata": {
        "id": "_krL2XGxJG0O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Min-max normalization"
      ]
    },
    {
      "metadata": {
        "id": "P54bFCWqM7Kn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# TODO normalization per feature vector (11)\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "Gd5WGRCJ3pxi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "norm_X_train = normalize(X_train, axis=0, norm='max')\n",
        "norm_X_val = normalize(X_val, axis=0, norm='max')\n",
        "norm_X_test = normalize(X_test, axis=0, norm='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FA5-P5rHKEGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "25dc85c5-bffb-463c-ace5-b18f383ca8c2"
      },
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X_train).describe()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>NCD_0</th>\n",
              "      <th>NCD_1</th>\n",
              "      <th>NCD_2</th>\n",
              "      <th>NCD_3</th>\n",
              "      <th>NCD_4</th>\n",
              "      <th>NCD_5</th>\n",
              "      <th>NCD_6</th>\n",
              "      <th>AI_0</th>\n",
              "      <th>AI_1</th>\n",
              "      <th>...</th>\n",
              "      <th>ADL_4</th>\n",
              "      <th>ADL_5</th>\n",
              "      <th>ADL_6</th>\n",
              "      <th>NAD_0</th>\n",
              "      <th>NAD_1</th>\n",
              "      <th>NAD_2</th>\n",
              "      <th>NAD_3</th>\n",
              "      <th>NAD_4</th>\n",
              "      <th>NAD_5</th>\n",
              "      <th>NAD_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.00000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>70314.643695</td>\n",
              "      <td>171.771998</td>\n",
              "      <td>154.786135</td>\n",
              "      <td>164.797495</td>\n",
              "      <td>176.272021</td>\n",
              "      <td>186.467341</td>\n",
              "      <td>215.67742</td>\n",
              "      <td>243.088116</td>\n",
              "      <td>87.067872</td>\n",
              "      <td>78.694277</td>\n",
              "      <td>...</td>\n",
              "      <td>1.038297</td>\n",
              "      <td>1.110372</td>\n",
              "      <td>1.193454</td>\n",
              "      <td>172.330409</td>\n",
              "      <td>155.265746</td>\n",
              "      <td>165.268811</td>\n",
              "      <td>176.761749</td>\n",
              "      <td>186.993370</td>\n",
              "      <td>216.244992</td>\n",
              "      <td>243.701006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>40590.715924</td>\n",
              "      <td>506.384320</td>\n",
              "      <td>468.363139</td>\n",
              "      <td>488.062360</td>\n",
              "      <td>522.865411</td>\n",
              "      <td>552.952547</td>\n",
              "      <td>626.37990</td>\n",
              "      <td>693.477620</td>\n",
              "      <td>235.195493</td>\n",
              "      <td>217.696152</td>\n",
              "      <td>...</td>\n",
              "      <td>1.314246</td>\n",
              "      <td>1.302927</td>\n",
              "      <td>1.583025</td>\n",
              "      <td>507.476487</td>\n",
              "      <td>469.249856</td>\n",
              "      <td>488.921779</td>\n",
              "      <td>523.796168</td>\n",
              "      <td>553.953944</td>\n",
              "      <td>627.412913</td>\n",
              "      <td>694.531571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>35112.750000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>70403.500000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>28.00000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>33.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>105457.250000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>161.00000</td>\n",
              "      <td>186.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.083333</td>\n",
              "      <td>1.100021</td>\n",
              "      <td>1.118081</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>187.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>140706.000000</td>\n",
              "      <td>24210.000000</td>\n",
              "      <td>22899.000000</td>\n",
              "      <td>20015.000000</td>\n",
              "      <td>27007.000000</td>\n",
              "      <td>30957.000000</td>\n",
              "      <td>28603.00000</td>\n",
              "      <td>27449.000000</td>\n",
              "      <td>10170.000000</td>\n",
              "      <td>10036.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>273.000000</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>239.000000</td>\n",
              "      <td>24301.000000</td>\n",
              "      <td>22980.000000</td>\n",
              "      <td>20083.000000</td>\n",
              "      <td>27071.000000</td>\n",
              "      <td>31028.000000</td>\n",
              "      <td>28697.000000</td>\n",
              "      <td>27557.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 78 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Unnamed: 0         NCD_0         NCD_1         NCD_2         NCD_3  \\\n",
              "count   90052.000000  90052.000000  90052.000000  90052.000000  90052.000000   \n",
              "mean    70314.643695    171.771998    154.786135    164.797495    176.272021   \n",
              "std     40590.715924    506.384320    468.363139    488.062360    522.865411   \n",
              "min         3.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%     35112.750000      3.000000      2.000000      3.000000      3.000000   \n",
              "50%     70403.500000     22.000000     19.000000     21.000000     22.000000   \n",
              "75%    105457.250000    125.000000    112.000000    119.000000    126.000000   \n",
              "max    140706.000000  24210.000000  22899.000000  20015.000000  27007.000000   \n",
              "\n",
              "              NCD_4        NCD_5         NCD_6          AI_0          AI_1  \\\n",
              "count  90052.000000  90052.00000  90052.000000  90052.000000  90052.000000   \n",
              "mean     186.467341    215.67742    243.088116     87.067872     78.694277   \n",
              "std      552.952547    626.37990    693.477620    235.195493    217.696152   \n",
              "min        0.000000      0.00000      0.000000      0.000000      0.000000   \n",
              "25%        3.000000      4.00000      6.000000      2.000000      2.000000   \n",
              "50%       23.000000     28.00000     33.000000     13.000000     11.000000   \n",
              "75%      133.000000    161.00000    186.000000     70.000000     64.000000   \n",
              "max    30957.000000  28603.00000  27449.000000  10170.000000  10036.000000   \n",
              "\n",
              "           ...              ADL_4         ADL_5         ADL_6         NAD_0  \\\n",
              "count      ...       90052.000000  90052.000000  90052.000000  90052.000000   \n",
              "mean       ...           1.038297      1.110372      1.193454    172.330409   \n",
              "std        ...           1.314246      1.302927      1.583025    507.476487   \n",
              "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
              "25%        ...           1.000000      1.000000      1.000000      3.000000   \n",
              "50%        ...           1.000000      1.000000      1.000000     22.000000   \n",
              "75%        ...           1.083333      1.100021      1.118081    125.000000   \n",
              "max        ...         273.000000    181.000000    239.000000  24301.000000   \n",
              "\n",
              "              NAD_1         NAD_2         NAD_3         NAD_4         NAD_5  \\\n",
              "count  90052.000000  90052.000000  90052.000000  90052.000000  90052.000000   \n",
              "mean     155.265746    165.268811    176.761749    186.993370    216.244992   \n",
              "std      469.249856    488.921779    523.796168    553.953944    627.412913   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        2.000000      3.000000      3.000000      3.000000      4.000000   \n",
              "50%       19.000000     21.000000     22.000000     23.000000     29.000000   \n",
              "75%      113.000000    120.000000    126.000000    133.000000    162.000000   \n",
              "max    22980.000000  20083.000000  27071.000000  31028.000000  28697.000000   \n",
              "\n",
              "              NAD_6  \n",
              "count  90052.000000  \n",
              "mean     243.701006  \n",
              "std      694.531571  \n",
              "min        0.000000  \n",
              "25%        6.000000  \n",
              "50%       33.000000  \n",
              "75%      187.000000  \n",
              "max    27557.000000  \n",
              "\n",
              "[8 rows x 78 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "oJgTV9KVKioF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "9f07cf32-86f2-4a50-ff13-0e1a521b93b2"
      },
      "cell_type": "code",
      "source": [
        "pd.DataFrame(norm_X_train).describe()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "      <td>90052.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.499727</td>\n",
              "      <td>0.007095</td>\n",
              "      <td>0.006760</td>\n",
              "      <td>0.008234</td>\n",
              "      <td>0.006527</td>\n",
              "      <td>0.006023</td>\n",
              "      <td>0.007540</td>\n",
              "      <td>0.008856</td>\n",
              "      <td>0.008561</td>\n",
              "      <td>0.007841</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003803</td>\n",
              "      <td>0.006135</td>\n",
              "      <td>0.004994</td>\n",
              "      <td>0.007091</td>\n",
              "      <td>0.006757</td>\n",
              "      <td>0.008229</td>\n",
              "      <td>0.006530</td>\n",
              "      <td>0.006027</td>\n",
              "      <td>0.007535</td>\n",
              "      <td>0.008844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.288479</td>\n",
              "      <td>0.020916</td>\n",
              "      <td>0.020453</td>\n",
              "      <td>0.024385</td>\n",
              "      <td>0.019360</td>\n",
              "      <td>0.017862</td>\n",
              "      <td>0.021899</td>\n",
              "      <td>0.025264</td>\n",
              "      <td>0.023126</td>\n",
              "      <td>0.021692</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004814</td>\n",
              "      <td>0.007198</td>\n",
              "      <td>0.006624</td>\n",
              "      <td>0.020883</td>\n",
              "      <td>0.020420</td>\n",
              "      <td>0.024345</td>\n",
              "      <td>0.019349</td>\n",
              "      <td>0.017853</td>\n",
              "      <td>0.021863</td>\n",
              "      <td>0.025203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.249547</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.000199</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003663</td>\n",
              "      <td>0.005525</td>\n",
              "      <td>0.004184</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.000218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500359</td>\n",
              "      <td>0.000909</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.001049</td>\n",
              "      <td>0.000815</td>\n",
              "      <td>0.000743</td>\n",
              "      <td>0.000979</td>\n",
              "      <td>0.001202</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>0.001096</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003663</td>\n",
              "      <td>0.005525</td>\n",
              "      <td>0.004184</td>\n",
              "      <td>0.000905</td>\n",
              "      <td>0.000827</td>\n",
              "      <td>0.001046</td>\n",
              "      <td>0.000813</td>\n",
              "      <td>0.000741</td>\n",
              "      <td>0.001011</td>\n",
              "      <td>0.001198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.749487</td>\n",
              "      <td>0.005163</td>\n",
              "      <td>0.004891</td>\n",
              "      <td>0.005946</td>\n",
              "      <td>0.004665</td>\n",
              "      <td>0.004296</td>\n",
              "      <td>0.005629</td>\n",
              "      <td>0.006776</td>\n",
              "      <td>0.006883</td>\n",
              "      <td>0.006377</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003968</td>\n",
              "      <td>0.006077</td>\n",
              "      <td>0.004678</td>\n",
              "      <td>0.005144</td>\n",
              "      <td>0.004917</td>\n",
              "      <td>0.005975</td>\n",
              "      <td>0.004654</td>\n",
              "      <td>0.004286</td>\n",
              "      <td>0.005645</td>\n",
              "      <td>0.006786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 78 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0             1             2             3             4   \\\n",
              "count  90052.000000  90052.000000  90052.000000  90052.000000  90052.000000   \n",
              "mean       0.499727      0.007095      0.006760      0.008234      0.006527   \n",
              "std        0.288479      0.020916      0.020453      0.024385      0.019360   \n",
              "min        0.000021      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.249547      0.000124      0.000087      0.000150      0.000111   \n",
              "50%        0.500359      0.000909      0.000830      0.001049      0.000815   \n",
              "75%        0.749487      0.005163      0.004891      0.005946      0.004665   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                 5             6             7             8             9   \\\n",
              "count  90052.000000  90052.000000  90052.000000  90052.000000  90052.000000   \n",
              "mean       0.006023      0.007540      0.008856      0.008561      0.007841   \n",
              "std        0.017862      0.021899      0.025264      0.023126      0.021692   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000097      0.000140      0.000219      0.000197      0.000199   \n",
              "50%        0.000743      0.000979      0.001202      0.001278      0.001096   \n",
              "75%        0.004296      0.005629      0.006776      0.006883      0.006377   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "           ...                 68            69            70            71  \\\n",
              "count      ...       90052.000000  90052.000000  90052.000000  90052.000000   \n",
              "mean       ...           0.003803      0.006135      0.004994      0.007091   \n",
              "std        ...           0.004814      0.007198      0.006624      0.020883   \n",
              "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
              "25%        ...           0.003663      0.005525      0.004184      0.000123   \n",
              "50%        ...           0.003663      0.005525      0.004184      0.000905   \n",
              "75%        ...           0.003968      0.006077      0.004678      0.005144   \n",
              "max        ...           1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                 72            73            74            75            76  \\\n",
              "count  90052.000000  90052.000000  90052.000000  90052.000000  90052.000000   \n",
              "mean       0.006757      0.008229      0.006530      0.006027      0.007535   \n",
              "std        0.020420      0.024345      0.019349      0.017853      0.021863   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000087      0.000149      0.000111      0.000097      0.000139   \n",
              "50%        0.000827      0.001046      0.000813      0.000741      0.001011   \n",
              "75%        0.004917      0.005975      0.004654      0.004286      0.005645   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                 77  \n",
              "count  90052.000000  \n",
              "mean       0.008844  \n",
              "std        0.025203  \n",
              "min        0.000000  \n",
              "25%        0.000218  \n",
              "50%        0.001198  \n",
              "75%        0.006786  \n",
              "max        1.000000  \n",
              "\n",
              "[8 rows x 78 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "GJDzQb-vr44v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model construction"
      ]
    },
    {
      "metadata": {
        "id": "DGSFx6e7r8Tm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Linear classifier"
      ]
    },
    {
      "metadata": {
        "id": "r5ENSY3srngi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IvNhwSA6sCmW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tree-based"
      ]
    },
    {
      "metadata": {
        "id": "X9kLuPhU6fza",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kfold = KFold(10, True, 1)\n",
        "stratified_kfold = KFold(10, True, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0NIvfOtVWmfN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Extra tree classifier"
      ]
    },
    {
      "metadata": {
        "id": "8OruSjxaWl4L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildET(X,Y,dt_criterion=\"gini\", dt_class_weight=None):\n",
        "  clf = tree.ExtraTreeClassifier(criterion=dt_criterion, class_weight=dt_class_weight)\n",
        "  return clf.fit(train_X, train_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jEuyVjAvWfTz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fe5d33f3-bd0c-472e-fc05-9ee44c0e4824"
      },
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(index=range(10))\n",
        "criteria = [\"gini\", \"entropy\"]\n",
        "class_weights=[\"balanced\"]\n",
        "col_name = \"%s_stratified_kfold_denorm_%s_%s\"\n",
        "for criterion in criteria:\n",
        "  for class_weight in class_weights:\n",
        "    f1s, w_aucs, bacc, tpr, tnr = [], [], [], [], []\n",
        "    for train_idx, test_idx in stratified_kfold.split(data_X):\n",
        "      train_X = data_X.iloc[train_idx]\n",
        "      test_X = data_X.iloc[test_idx]\n",
        "      train_Y, test_Y = data_Y.iloc[train_idx], data_Y.iloc[test_idx]\n",
        "      clf = buildET(train_X, train_Y, dt_criterion=criterion, dt_class_weight=class_weight)\n",
        "      pred_Y = clf.predict(test_X)\n",
        "      f1s.append(f1_score(test_Y, pred_Y))\n",
        "      w_aucs.append(roc_auc_score(test_Y, pred_Y, average=\"weighted\"))\n",
        "      tn, fp, fn, tp = confusion_matrix(test_Y, pred_Y).ravel()\n",
        "      bacc.append(balanced_accuracy_score(test_Y, pred_Y))\n",
        "      tpr.append(tp/(tp+fn))\n",
        "      tnr.append(tn/(fp+tn))\n",
        "    print(f'{criterion}')\n",
        "    f1_df = pd.DataFrame({col_name % (\"F1\", criterion, str(class_weight)): f1s})\n",
        "    auc_df = pd.DataFrame({col_name % (\"AUC\", criterion, str(class_weight)): w_aucs})\n",
        "    bacc_df = pd.DataFrame({col_name % (\"BACC\", criterion, str(class_weight)): bacc})\n",
        "    tpr_df = pd.DataFrame({col_name % (\"TPR\", criterion, str(class_weight)): tpr})\n",
        "    tnr_df = pd.DataFrame({col_name % (\"TNR\", criterion, str(class_weight)): tnr})\n",
        "    results = pd.concat([results, f1_df, auc_df, bacc_df, tpr_df, tnr_df], axis=1)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gini\n",
            "entropy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z18xpSwqZ1VJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bf5c96aa-9486-4c5f-dc1d-76f00440e00e"
      },
      "cell_type": "code",
      "source": [
        "results.describe().iloc[1]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "F1_stratified_kfold_denorm_gini_balanced         0.412740\n",
              "AUC_stratified_kfold_denorm_gini_balanced        0.692178\n",
              "BACC_stratified_kfold_denorm_gini_balanced       0.692178\n",
              "TPR_stratified_kfold_denorm_gini_balanced        0.398311\n",
              "TNR_stratified_kfold_denorm_gini_balanced        0.986044\n",
              "F1_stratified_kfold_denorm_entropy_balanced      0.429436\n",
              "AUC_stratified_kfold_denorm_entropy_balanced     0.705552\n",
              "BACC_stratified_kfold_denorm_entropy_balanced    0.705552\n",
              "TPR_stratified_kfold_denorm_entropy_balanced     0.425716\n",
              "TNR_stratified_kfold_denorm_entropy_balanced     0.985388\n",
              "Name: mean, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "2tJbtReStTX9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Decision tree classifier"
      ]
    },
    {
      "metadata": {
        "id": "63Qtnys6HHWK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Normalized data"
      ]
    },
    {
      "metadata": {
        "id": "3uld_7xQ72wH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c31daf59-974b-4b6f-a648-6e4f7b0906c7"
      },
      "cell_type": "code",
      "source": [
        "f1s = []\n",
        "w_aucs = []\n",
        "for train_idx, test_idx in kfold.split(data_X):\n",
        "  train_X = normalize(data_X.iloc[train_idx], axis=0, norm='max')\n",
        "  test_X = normalize(data_X.iloc[test_idx], axis=0, norm='max')\n",
        "  train_Y, test_Y = data_Y.iloc[train_idx], data_Y.iloc[test_idx]\n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "  clf = clf.fit(train_X, train_Y)\n",
        "  pred_Y = clf.predict(test_X)\n",
        "  f1s.append(f1_score(test_Y, pred_Y))\n",
        "  w_aucs.append(roc_auc_score(test_Y, pred_Y, average=\"weighted\"))\n",
        "  print(f'Fold {len(f1s)}')\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Fold 2\n",
            "Fold 3\n",
            "Fold 4\n",
            "Fold 5\n",
            "Fold 6\n",
            "Fold 7\n",
            "Fold 8\n",
            "Fold 9\n",
            "Fold 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3nHIsoq6EGJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a6988f43-85b4-4797-f455-dc8c3eefaacb"
      },
      "cell_type": "code",
      "source": [
        "strat_f1s = []\n",
        "strat_w_aucs = []\n",
        "for train_idx, test_idx in stratified_kfold.split(data_X):\n",
        "  train_X = normalize(data_X.iloc[train_idx], axis=0, norm='max')\n",
        "  test_X = normalize(data_X.iloc[test_idx], axis=0, norm='max')\n",
        "  train_Y, test_Y = data_Y.iloc[train_idx], data_Y.iloc[test_idx]\n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "  clf = clf.fit(train_X, train_Y)\n",
        "  pred_Y = clf.predict(test_X)\n",
        "  strat_f1s.append(f1_score(test_Y, pred_Y))\n",
        "  strat_w_aucs.append(roc_auc_score(test_Y, pred_Y, average=\"weighted\"))\n",
        "  print(f'Fold {len(f1s)}')\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 10\n",
            "Fold 10\n",
            "Fold 10\n",
            "Fold 10\n",
            "Fold 10\n",
            "Fold 10\n",
            "Fold 10\n",
            "Fold 10\n",
            "Fold 10\n",
            "Fold 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hbzSYt0UDvw_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d300b2a9-49eb-42de-e042-e891d19eb91c"
      },
      "cell_type": "code",
      "source": [
        "print(pd.DataFrame(pd.concat([pd.DataFrame({\"F1\":f1s}),pd.DataFrame({\"Strat F1\":strat_f1s})], axis=1)))\n",
        "print(pd.DataFrame(pd.concat([pd.DataFrame({\"w_AUC\":w_aucs}),pd.DataFrame({\"Strat w_auc\":strat_w_aucs})], axis=1)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         F1  Strat F1\n",
            "0  0.195397  0.184303\n",
            "1  0.212994  0.224354\n",
            "2  0.193211  0.170330\n",
            "3  0.251185  0.249800\n",
            "4  0.212000  0.243012\n",
            "5  0.181729  0.168999\n",
            "6  0.225198  0.207916\n",
            "7  0.225502  0.235702\n",
            "8  0.365874  0.348485\n",
            "9  0.285714  0.303585\n",
            "      w_AUC  Strat w_auc\n",
            "0  0.773348     0.750088\n",
            "1  0.693776     0.688433\n",
            "2  0.740431     0.695476\n",
            "3  0.696530     0.692815\n",
            "4  0.743157     0.753593\n",
            "5  0.720147     0.690503\n",
            "6  0.723814     0.690914\n",
            "7  0.709674     0.725858\n",
            "8  0.760986     0.766432\n",
            "9  0.731688     0.732518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VcHWrShBGyJm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### denormalized data"
      ]
    },
    {
      "metadata": {
        "id": "ebqiyydkGn-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7e6bb37d-8df8-4e99-86ef-21286ac31bdf"
      },
      "cell_type": "code",
      "source": [
        "f1s = []\n",
        "w_aucs = []\n",
        "for train_idx, test_idx in kfold.split(data_X):\n",
        "  train_X = data_X.iloc[train_idx]\n",
        "  test_X = data_X.iloc[test_idx]\n",
        "  train_Y, test_Y = data_Y.iloc[train_idx], data_Y.iloc[test_idx]\n",
        "  clf = tree.DecisionTreeClassifier(criterion=\"entropy\", class_weight=\"balanced\")\n",
        "  clf = clf.fit(train_X, train_Y)\n",
        "  pred_Y = clf.predict(test_X)\n",
        "  f1s.append(f1_score(test_Y, pred_Y))\n",
        "  w_aucs.append(roc_auc_score(test_Y, pred_Y, average=\"weighted\"))\n",
        "  print(f'Fold {len(f1s)}')\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Fold 2\n",
            "Fold 3\n",
            "Fold 4\n",
            "Fold 5\n",
            "Fold 6\n",
            "Fold 7\n",
            "Fold 8\n",
            "Fold 9\n",
            "Fold 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oSprVQe_G7sV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "91ae70ef-0261-4fe7-8bdf-0e17798d4286"
      },
      "cell_type": "code",
      "source": [
        "strat_f1s = []\n",
        "strat_w_aucs = []\n",
        "for train_idx, test_idx in stratified_kfold.split(data_X):\n",
        "  train_X = data_X.iloc[train_idx]\n",
        "  test_X = data_X.iloc[test_idx]\n",
        "  train_Y, test_Y = data_Y.iloc[train_idx], data_Y.iloc[test_idx]\n",
        "  clf = tree.DecisionTreeClassifier(criterion=\"entropy\", class_weight=\"balanced\")\n",
        "  clf = clf.fit(train_X, train_Y)\n",
        "  pred_Y = clf.predict(test_X)\n",
        "  strat_f1s.append(f1_score(test_Y, pred_Y))\n",
        "  strat_w_aucs.append(roc_auc_score(test_Y, pred_Y, average=\"weighted\"))\n",
        "  print(f'Fold {len(strat_f1s)}')\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Fold 2\n",
            "Fold 3\n",
            "Fold 4\n",
            "Fold 5\n",
            "Fold 6\n",
            "Fold 7\n",
            "Fold 8\n",
            "Fold 9\n",
            "Fold 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CCl3V7oKHCKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "77c3c14f-bfb0-4449-a044-55d299298dcd"
      },
      "cell_type": "code",
      "source": [
        "print(pd.DataFrame(pd.concat([pd.DataFrame({\"F1\":f1s}),pd.DataFrame({\"Strat F1\":strat_f1s})], axis=1)))\n",
        "print(pd.DataFrame(pd.concat([pd.DataFrame({\"w_AUC\":w_aucs}),pd.DataFrame({\"Strat w_auc\":strat_w_aucs})], axis=1)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         F1  Strat F1\n",
            "0  0.423803  0.416787\n",
            "1  0.506849  0.519444\n",
            "2  0.423756  0.414977\n",
            "3  0.469444  0.455307\n",
            "4  0.425287  0.434659\n",
            "5  0.455090  0.447407\n",
            "6  0.468244  0.476904\n",
            "7  0.436997  0.446837\n",
            "8  0.442455  0.458599\n",
            "9  0.478947  0.478203\n",
            "      w_AUC  Strat w_auc\n",
            "0  0.710956     0.707816\n",
            "1  0.760091     0.763419\n",
            "2  0.701876     0.702836\n",
            "3  0.730883     0.722360\n",
            "4  0.699236     0.706091\n",
            "5  0.719638     0.717859\n",
            "6  0.719694     0.723501\n",
            "7  0.706533     0.710689\n",
            "8  0.711683     0.720712\n",
            "9  0.729892     0.728663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a8RsqtbHKvle",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Run multiple experiments"
      ]
    },
    {
      "metadata": {
        "id": "V7opB_9IKzwB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildDT(X,Y,dt_criterion=\"gini\", dt_class_weight=None):\n",
        "  clf = tree.DecisionTreeClassifier(criterion=dt_criterion, class_weight=dt_class_weight)\n",
        "  return clf.fit(train_X, train_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WXfqMfLZLSsi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(index=range(10))\n",
        "criteria = [\"gini\", \"entropy\"]\n",
        "class_weights=[\"balanced\"]\n",
        "col_name = \"%s_stratified_kfold_denorm_%s_%s\"\n",
        "for criterion in criteria:\n",
        "  for class_weight in class_weights:\n",
        "    f1s, w_aucs, bacc, tpr, tnr = [], [], [], [], []\n",
        "    for train_idx, test_idx in stratified_kfold.split(data_X):\n",
        "      train_X = data_X.iloc[train_idx]\n",
        "      test_X = data_X.iloc[test_idx]\n",
        "      train_Y, test_Y = data_Y.iloc[train_idx], data_Y.iloc[test_idx]\n",
        "      clf = buildDT(train_X, train_Y, dt_criterion=criterion, dt_class_weight=class_weight)\n",
        "      pred_Y = clf.predict(test_X)\n",
        "      f1s.append(f1_score(test_Y, pred_Y))\n",
        "      w_aucs.append(roc_auc_score(test_Y, pred_Y, average=\"weighted\"))\n",
        "      tn, fp, fn, tp = confusion_matrix(test_Y, pred_Y).ravel()\n",
        "      bacc.append(balanced_accuracy_score(test_Y, pred_Y))\n",
        "      tpr.append(tp/(tp+fn))\n",
        "      tnr.append(tn/(fp+tn))\n",
        "    print(f'{criterion}')\n",
        "    f1_df = pd.DataFrame({col_name % (\"F1\", criterion, str(class_weight)): f1s})\n",
        "    auc_df = pd.DataFrame({col_name % (\"AUC\", criterion, str(class_weight)): w_aucs})\n",
        "    bacc_df = pd.DataFrame({col_name % (\"BACC\", criterion, str(class_weight)): bacc})\n",
        "    tpr_df = pd.DataFrame({col_name % (\"TPR\", criterion, str(class_weight)): tpr})\n",
        "    tnr_df = pd.DataFrame({col_name % (\"TNR\", criterion, str(class_weight)): tnr})\n",
        "    results = pd.concat([results, f1_df, auc_df, bacc_df, tpr_df, tnr_df], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GFckeEQhXuy9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qritQrBHNpY_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Denormalized results"
      ]
    },
    {
      "metadata": {
        "id": "0n8M1_9_LOJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "25ea9632-d967-46a2-c4e2-397c7facebb5"
      },
      "cell_type": "code",
      "source": [
        "criteria = [\"gini\", \"entropy\"]\n",
        "class_weights=[\"balanced\"]\n",
        "col_name = \"%s_stratified_kfold_denorm_%s_%s\"\n",
        "for criterion in criteria:\n",
        "  for class_weight in class_weights:\n",
        "    f1s, w_aucs, bacc, tpr, tnr = [], [], [], [], []\n",
        "    for train_idx, test_idx in stratified_kfold.split(data_X):\n",
        "      train_X = data_X.iloc[train_idx]\n",
        "      test_X = data_X.iloc[test_idx]\n",
        "      train_Y, test_Y = data_Y.iloc[train_idx], data_Y.iloc[test_idx]\n",
        "      clf = buildDT(train_X, train_Y, dt_criterion=criterion, dt_class_weight=class_weight)\n",
        "      pred_Y = clf.predict(test_X)\n",
        "      f1s.append(f1_score(test_Y, pred_Y))\n",
        "      w_aucs.append(roc_auc_score(test_Y, pred_Y, average=\"weighted\"))\n",
        "      tn, fp, fn, tp = confusion_matrix(test_Y, pred_Y).ravel()\n",
        "      bacc.append(balanced_accuracy_score(test_Y, pred_Y))\n",
        "      tpr.append(tp/(tp+fn))\n",
        "      tnr.append(tn/(fp+tn))\n",
        "    print(f'{criterion}')\n",
        "    f1_df = pd.DataFrame({col_name % (\"F1\", criterion, str(class_weight)): f1s})\n",
        "    auc_df = pd.DataFrame({col_name % (\"AUC\", criterion, str(class_weight)): w_aucs})\n",
        "    bacc_df = pd.DataFrame({col_name % (\"BACC\", criterion, str(class_weight)): bacc})\n",
        "    tpr_df = pd.DataFrame({col_name % (\"TPR\", criterion, str(class_weight)): tpr})\n",
        "    tnr_df = pd.DataFrame({col_name % (\"TNR\", criterion, str(class_weight)): tnr})\n",
        "    results = pd.concat([results, f1_df, auc_df, bacc_df, tpr_df, tnr_df], axis=1)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gini\n",
            "entropy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-RMoLNWDNiPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "70d2a907-2061-481a-d288-ca1ab15d081e"
      },
      "cell_type": "code",
      "source": [
        "results"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1_stratified_kfold_denorm_gini_balanced</th>\n",
              "      <th>AUC_stratified_kfold_denorm_gini_balanced</th>\n",
              "      <th>BACC_stratified_kfold_denorm_gini_balanced</th>\n",
              "      <th>TPR_stratified_kfold_denorm_gini_balanced</th>\n",
              "      <th>TNR_stratified_kfold_denorm_gini_balanced</th>\n",
              "      <th>F1_stratified_kfold_denorm_entropy_balanced</th>\n",
              "      <th>AUC_stratified_kfold_denorm_entropy_balanced</th>\n",
              "      <th>BACC_stratified_kfold_denorm_entropy_balanced</th>\n",
              "      <th>TPR_stratified_kfold_denorm_entropy_balanced</th>\n",
              "      <th>TNR_stratified_kfold_denorm_entropy_balanced</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.427935</td>\n",
              "      <td>0.708471</td>\n",
              "      <td>0.708471</td>\n",
              "      <td>0.431138</td>\n",
              "      <td>0.985805</td>\n",
              "      <td>0.418605</td>\n",
              "      <td>0.707925</td>\n",
              "      <td>0.707925</td>\n",
              "      <td>0.431138</td>\n",
              "      <td>0.984713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.460870</td>\n",
              "      <td>0.723029</td>\n",
              "      <td>0.723029</td>\n",
              "      <td>0.459538</td>\n",
              "      <td>0.986521</td>\n",
              "      <td>0.513966</td>\n",
              "      <td>0.759120</td>\n",
              "      <td>0.759120</td>\n",
              "      <td>0.531792</td>\n",
              "      <td>0.986448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.389937</td>\n",
              "      <td>0.688495</td>\n",
              "      <td>0.688495</td>\n",
              "      <td>0.391167</td>\n",
              "      <td>0.985822</td>\n",
              "      <td>0.407643</td>\n",
              "      <td>0.695240</td>\n",
              "      <td>0.695240</td>\n",
              "      <td>0.403785</td>\n",
              "      <td>0.986695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.457300</td>\n",
              "      <td>0.726330</td>\n",
              "      <td>0.726330</td>\n",
              "      <td>0.467606</td>\n",
              "      <td>0.985054</td>\n",
              "      <td>0.472185</td>\n",
              "      <td>0.737488</td>\n",
              "      <td>0.737488</td>\n",
              "      <td>0.490141</td>\n",
              "      <td>0.984835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.422695</td>\n",
              "      <td>0.700337</td>\n",
              "      <td>0.700337</td>\n",
              "      <td>0.415042</td>\n",
              "      <td>0.985633</td>\n",
              "      <td>0.421203</td>\n",
              "      <td>0.697734</td>\n",
              "      <td>0.697734</td>\n",
              "      <td>0.409471</td>\n",
              "      <td>0.985998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.400602</td>\n",
              "      <td>0.690818</td>\n",
              "      <td>0.690818</td>\n",
              "      <td>0.395833</td>\n",
              "      <td>0.985803</td>\n",
              "      <td>0.456036</td>\n",
              "      <td>0.721053</td>\n",
              "      <td>0.721053</td>\n",
              "      <td>0.455357</td>\n",
              "      <td>0.986749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.450633</td>\n",
              "      <td>0.707727</td>\n",
              "      <td>0.707727</td>\n",
              "      <td>0.429952</td>\n",
              "      <td>0.985502</td>\n",
              "      <td>0.462112</td>\n",
              "      <td>0.717132</td>\n",
              "      <td>0.717132</td>\n",
              "      <td>0.449275</td>\n",
              "      <td>0.984989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.421199</td>\n",
              "      <td>0.691405</td>\n",
              "      <td>0.691405</td>\n",
              "      <td>0.396325</td>\n",
              "      <td>0.986485</td>\n",
              "      <td>0.432935</td>\n",
              "      <td>0.706277</td>\n",
              "      <td>0.706277</td>\n",
              "      <td>0.427822</td>\n",
              "      <td>0.984732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.435724</td>\n",
              "      <td>0.697588</td>\n",
              "      <td>0.697588</td>\n",
              "      <td>0.408629</td>\n",
              "      <td>0.986546</td>\n",
              "      <td>0.443286</td>\n",
              "      <td>0.708314</td>\n",
              "      <td>0.708314</td>\n",
              "      <td>0.431472</td>\n",
              "      <td>0.985156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.424411</td>\n",
              "      <td>0.692497</td>\n",
              "      <td>0.692497</td>\n",
              "      <td>0.398438</td>\n",
              "      <td>0.986556</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.732605</td>\n",
              "      <td>0.732605</td>\n",
              "      <td>0.479167</td>\n",
              "      <td>0.986044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   F1_stratified_kfold_denorm_gini_balanced  \\\n",
              "0                                  0.427935   \n",
              "1                                  0.460870   \n",
              "2                                  0.389937   \n",
              "3                                  0.457300   \n",
              "4                                  0.422695   \n",
              "5                                  0.400602   \n",
              "6                                  0.450633   \n",
              "7                                  0.421199   \n",
              "8                                  0.435724   \n",
              "9                                  0.424411   \n",
              "\n",
              "   AUC_stratified_kfold_denorm_gini_balanced  \\\n",
              "0                                   0.708471   \n",
              "1                                   0.723029   \n",
              "2                                   0.688495   \n",
              "3                                   0.726330   \n",
              "4                                   0.700337   \n",
              "5                                   0.690818   \n",
              "6                                   0.707727   \n",
              "7                                   0.691405   \n",
              "8                                   0.697588   \n",
              "9                                   0.692497   \n",
              "\n",
              "   BACC_stratified_kfold_denorm_gini_balanced  \\\n",
              "0                                    0.708471   \n",
              "1                                    0.723029   \n",
              "2                                    0.688495   \n",
              "3                                    0.726330   \n",
              "4                                    0.700337   \n",
              "5                                    0.690818   \n",
              "6                                    0.707727   \n",
              "7                                    0.691405   \n",
              "8                                    0.697588   \n",
              "9                                    0.692497   \n",
              "\n",
              "   TPR_stratified_kfold_denorm_gini_balanced  \\\n",
              "0                                   0.431138   \n",
              "1                                   0.459538   \n",
              "2                                   0.391167   \n",
              "3                                   0.467606   \n",
              "4                                   0.415042   \n",
              "5                                   0.395833   \n",
              "6                                   0.429952   \n",
              "7                                   0.396325   \n",
              "8                                   0.408629   \n",
              "9                                   0.398438   \n",
              "\n",
              "   TNR_stratified_kfold_denorm_gini_balanced  \\\n",
              "0                                   0.985805   \n",
              "1                                   0.986521   \n",
              "2                                   0.985822   \n",
              "3                                   0.985054   \n",
              "4                                   0.985633   \n",
              "5                                   0.985803   \n",
              "6                                   0.985502   \n",
              "7                                   0.986485   \n",
              "8                                   0.986546   \n",
              "9                                   0.986556   \n",
              "\n",
              "   F1_stratified_kfold_denorm_entropy_balanced  \\\n",
              "0                                     0.418605   \n",
              "1                                     0.513966   \n",
              "2                                     0.407643   \n",
              "3                                     0.472185   \n",
              "4                                     0.421203   \n",
              "5                                     0.456036   \n",
              "6                                     0.462112   \n",
              "7                                     0.432935   \n",
              "8                                     0.443286   \n",
              "9                                     0.484848   \n",
              "\n",
              "   AUC_stratified_kfold_denorm_entropy_balanced  \\\n",
              "0                                      0.707925   \n",
              "1                                      0.759120   \n",
              "2                                      0.695240   \n",
              "3                                      0.737488   \n",
              "4                                      0.697734   \n",
              "5                                      0.721053   \n",
              "6                                      0.717132   \n",
              "7                                      0.706277   \n",
              "8                                      0.708314   \n",
              "9                                      0.732605   \n",
              "\n",
              "   BACC_stratified_kfold_denorm_entropy_balanced  \\\n",
              "0                                       0.707925   \n",
              "1                                       0.759120   \n",
              "2                                       0.695240   \n",
              "3                                       0.737488   \n",
              "4                                       0.697734   \n",
              "5                                       0.721053   \n",
              "6                                       0.717132   \n",
              "7                                       0.706277   \n",
              "8                                       0.708314   \n",
              "9                                       0.732605   \n",
              "\n",
              "   TPR_stratified_kfold_denorm_entropy_balanced  \\\n",
              "0                                      0.431138   \n",
              "1                                      0.531792   \n",
              "2                                      0.403785   \n",
              "3                                      0.490141   \n",
              "4                                      0.409471   \n",
              "5                                      0.455357   \n",
              "6                                      0.449275   \n",
              "7                                      0.427822   \n",
              "8                                      0.431472   \n",
              "9                                      0.479167   \n",
              "\n",
              "   TNR_stratified_kfold_denorm_entropy_balanced  \n",
              "0                                      0.984713  \n",
              "1                                      0.986448  \n",
              "2                                      0.986695  \n",
              "3                                      0.984835  \n",
              "4                                      0.985998  \n",
              "5                                      0.986749  \n",
              "6                                      0.984989  \n",
              "7                                      0.984732  \n",
              "8                                      0.985156  \n",
              "9                                      0.986044  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "metadata": {
        "id": "IbW95n6SNtSn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Normalized results"
      ]
    },
    {
      "metadata": {
        "id": "Wipp3tF8Nokl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "07bd0e7d-765a-40cd-b70c-353946a16eeb"
      },
      "cell_type": "code",
      "source": [
        "criteria = [\"gini\", \"entropy\"]\n",
        "class_weights=[\"balanced\"]\n",
        "col_name = \"%s_stratified_kfold_norm_%s_%s\"\n",
        "for criterion in criteria:\n",
        "  for class_weight in class_weights:\n",
        "    f1s, w_aucs, bacc, tpr, tnr = [], [], [], [], []\n",
        "    for train_idx, test_idx in stratified_kfold.split(data_X):\n",
        "      train_X = normalize(data_X.iloc[train_idx], axis=0, norm='max')\n",
        "      test_X = normalize(data_X.iloc[test_idx], axis=0, norm='max')\n",
        "      train_Y, test_Y = data_Y.iloc[train_idx], data_Y.iloc[test_idx]\n",
        "      N = sum(test_Y)\n",
        "      P = len(test_Y)-N\n",
        "      clf = buildDT(train_X, train_Y, dt_criterion=criterion, dt_class_weight=class_weight)\n",
        "      pred_Y = clf.predict(test_X)\n",
        "      f1s.append(f1_score(test_Y, pred_Y))\n",
        "      w_aucs.append(roc_auc_score(test_Y, pred_Y, average=\"weighted\"))\n",
        "      tn, fp, fn, tp = confusion_matrix(test_Y, pred_Y).ravel()\n",
        "      bacc.append(balanced_accuracy_score(test_Y, pred_Y))\n",
        "      tpr.append(tp/(tp+fn))\n",
        "      tnr.append(tn/(fp+tn))\n",
        "    print(f'{criterion}')\n",
        "    f1_df = pd.DataFrame({col_name % (\"F1\", criterion, str(class_weight)): f1s})\n",
        "    auc_df = pd.DataFrame({col_name % (\"AUC\", criterion, str(class_weight)): w_aucs})\n",
        "    bacc_df = pd.DataFrame({col_name % (\"BACC\", criterion, str(class_weight)): bacc})\n",
        "    tpr_df = pd.DataFrame({col_name % (\"TPR\", criterion, str(class_weight)): tpr})\n",
        "    tnr_df = pd.DataFrame({col_name % (\"TNR\", criterion, str(class_weight)): tnr})\n",
        "    results = pd.concat([results, f1_df, auc_df, bacc_df, tpr_df, tnr_df], axis=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gini\n",
            "entropy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ovke1s8CPBLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "54ac7aac-de6a-41e1-b71d-c8583c4dd83b"
      },
      "cell_type": "code",
      "source": [
        "results.describe().iloc[1]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "F1_stratified_kfold_denorm_gini_balanced         0.430198\n",
              "AUC_stratified_kfold_denorm_gini_balanced        0.703738\n",
              "BACC_stratified_kfold_denorm_gini_balanced       0.703738\n",
              "TPR_stratified_kfold_denorm_gini_balanced        0.421605\n",
              "TNR_stratified_kfold_denorm_gini_balanced        0.985870\n",
              "F1_stratified_kfold_denorm_entropy_balanced      0.456540\n",
              "AUC_stratified_kfold_denorm_entropy_balanced     0.721000\n",
              "BACC_stratified_kfold_denorm_entropy_balanced    0.721000\n",
              "TPR_stratified_kfold_denorm_entropy_balanced     0.456233\n",
              "TNR_stratified_kfold_denorm_entropy_balanced     0.985767\n",
              "F1_stratified_kfold_norm_gini_balanced           0.057304\n",
              "AUC_stratified_kfold_norm_gini_balanced          0.515324\n",
              "BACC_stratified_kfold_norm_gini_balanced         0.515324\n",
              "TPR_stratified_kfold_norm_gini_balanced          0.043239\n",
              "TNR_stratified_kfold_norm_gini_balanced          0.987410\n",
              "F1_stratified_kfold_norm_entropy_balanced        0.308010\n",
              "AUC_stratified_kfold_norm_entropy_balanced       0.639634\n",
              "BACC_stratified_kfold_norm_entropy_balanced      0.639634\n",
              "TPR_stratified_kfold_norm_entropy_balanced       0.295609\n",
              "TNR_stratified_kfold_norm_entropy_balanced       0.983659\n",
              "Name: mean, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "gFMpui5dSzHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "068db023-b3bc-4b29-85bb-e60e502741df"
      },
      "cell_type": "code",
      "source": [
        "results.filter(regex=\"stratified_kfold_denorm_en\").describe().iloc[1]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "F1_stratified_kfold_denorm_entropy_balanced      0.456540\n",
              "AUC_stratified_kfold_denorm_entropy_balanced     0.721000\n",
              "BACC_stratified_kfold_denorm_entropy_balanced    0.721000\n",
              "TPR_stratified_kfold_denorm_entropy_balanced     0.456233\n",
              "TNR_stratified_kfold_denorm_entropy_balanced     0.985767\n",
              "Name: mean, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "LcwSgD5aGF85",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results.describe().iloc[1].to_csv(PATH_PREFIX + \"DT_results_5metrics\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pUvptHhwcDom",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "res.to_csv(PATH_PREFIX + \"DT_results_str-kfold_denorm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_jcAlTRyGBz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "r.to_csv(PATH_PREFIX + \"DT_results_str-kfold_norm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SyjkCjBXyGIQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "res = pd.DataFrame()\n",
        "criteria = [\"gini\", \"entropy\"]\n",
        "class_weights=[\"balanced\"]\n",
        "col_name = \"%s_str-kfold_denorm_%s_%s\"\n",
        "for criterion in criteria:\n",
        "  for class_weight in class_weights:\n",
        "    f1s, w_aucs = [], []\n",
        "    for train_idx, test_idx in stratified_kfold.split(data_X):\n",
        "      train_X = data_X.iloc[train_idx]\n",
        "      test_X = data_X.iloc[test_idx]\n",
        "      train_Y, test_Y = data_Y.iloc[train_idx], data_Y.iloc[test_idx]\n",
        "      clf = buildDT(train_X, train_Y, dt_criterion=criterion, dt_class_weight=class_weight)\n",
        "      pred_Y = clf.predict(test_X)\n",
        "      f1s.append(f1_score(test_Y, pred_Y))\n",
        "      w_aucs.append(roc_auc_score(test_Y, pred_Y, average=\"weighted\"))\n",
        "      print(f'Fold {len(f1s)}')\n",
        "    f1_df = pd.DataFrame({col_name % (\"F1\", criterion, str(class_weight)): f1s})\n",
        "    auc_df = pd.DataFrame({col_name % (\"WAUC\", criterion, str(class_weight)): w_aucs})\n",
        "    res = pd.concat([res, f1_df, auc_df], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_LBeEj09Fs49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d9bb4b1f-658c-4588-808c-d97e3d9887b1"
      },
      "cell_type": "code",
      "source": [
        "r = pd.DataFrame()\n",
        "criteria = [\"gini\", \"entropy\"]\n",
        "class_weights=[\"balanced\"]\n",
        "col_name = \"%s_str-kfold_norm_%s_%s\"\n",
        "for criterion in criteria:\n",
        "  for class_weight in class_weights:\n",
        "    f1s, w_aucs = [], []\n",
        "    for train_idx, test_idx in stratified_kfold.split(data_X):\n",
        "      train_X = normalize(data_X.iloc[train_idx], axis=0, norm='max')\n",
        "      test_X = normalize(data_X.iloc[test_idx], axis=0, norm='max')\n",
        "      train_Y, test_Y = data_Y.iloc[train_idx], data_Y.iloc[test_idx]\n",
        "      clf = buildDT(train_X, train_Y, dt_criterion=criterion, dt_class_weight=class_weight)\n",
        "      pred_Y = clf.predict(test_X)\n",
        "      f1s.append(f1_score(test_Y, pred_Y))\n",
        "      w_aucs.append(roc_auc_score(test_Y, pred_Y, average=\"weighted\"))\n",
        "      print(f'Fold {len(f1s)}')\n",
        "    f1_df = pd.DataFrame({col_name % (\"F1\", criterion, str(class_weight)): f1s})\n",
        "    auc_df = pd.DataFrame({col_name % (\"WAUC\", criterion, str(class_weight)): w_aucs})\n",
        "    r = pd.concat([r, f1_df, auc_df], axis=1)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Fold 2\n",
            "Fold 3\n",
            "Fold 4\n",
            "Fold 5\n",
            "Fold 6\n",
            "Fold 7\n",
            "Fold 8\n",
            "Fold 9\n",
            "Fold 10\n",
            "Fold 1\n",
            "Fold 2\n",
            "Fold 3\n",
            "Fold 4\n",
            "Fold 5\n",
            "Fold 6\n",
            "Fold 7\n",
            "Fold 8\n",
            "Fold 9\n",
            "Fold 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cx1H9gMUKetB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "AYXMdKNDKcWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "0c7fd426-c0f3-456f-e589-fd8f7cf9995d"
      },
      "cell_type": "code",
      "source": [
        "(results[\"F1_kfold_denorm_gini_None\"]-results[\"WAUC_kfold_denorm_gini_None\"]).plot(kind='hist', title= 'Difference Histogram')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f197cd61a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFZCAYAAACBlraEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncAhCHQAAh/h/qq9oYSXMwa4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9luL_gnktfWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69317250-19e6-4ebf-b14b-0172700fcdc3"
      },
      "cell_type": "code",
      "source": [
        "clf.score(X_test, Y_test) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9710752611754673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "5HqSK-aUuAAp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3iDFTo4ltY_A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8zyPMILht6hV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_pred = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zs_CZuy_vINN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6ade0c61-124b-4b69-c373-de20b0d24d8f"
      },
      "cell_type": "code",
      "source": [
        "f1 = f1_score(Y_test, Y_pred)\n",
        "f1_macro = f1_score(Y_test, Y_pred, average='macro')\n",
        "f1_micro = f1_score(Y_test, Y_pred, average='micro')\n",
        "f1_weighted = f1_score(Y_test, Y_pred, average='weighted')\n",
        "\n",
        "\n",
        "print(f\"\"\"F1 score: {f1}\n",
        "F1 macro: {f1_macro}\n",
        "F1 micro: {f1_micro}\n",
        "F1 weighted: {f1_weighted}\"\"\")\n",
        "# auc_score = auc(Y_test, Y_pred)\n",
        "acc = accuracy_score(Y_test, Y_pred)\n",
        "cm = confusion_matrix(Y_test, Y_pred)\n",
        "prec = precision_score(Y_test, Y_pred)\n",
        "rec = recall_score(Y_test, Y_pred)\n",
        "w_auc = roc_auc_score(Y_test, Y_pred, average=\"weighted\")\n",
        "auc = roc_auc_score(Y_test, Y_pred)\n",
        "\n",
        "w_acc = balanced_accuracy_score(Y_test, Y_pred)\n",
        "print(f\"\"\"\n",
        "Accuracy: {acc}\n",
        "confusion_matrix: {cm}\n",
        "Precision: {prec}\n",
        "Recall: {rec}\n",
        "Weighted auc: {w_auc}\n",
        "Auc: {auc}\n",
        "Weighted acc: {w_acc}\"\"\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: 0.45387205387205387\n",
            "F1 macro: 0.7195362568672301\n",
            "F1 micro: 0.9711818634070073\n",
            "F1 weighted: 0.9723618799436571\n",
            "\n",
            "Accuracy: 0.9711818634070073\n",
            "confusion_matrix: [[26994   468]\n",
            " [  343   337]]\n",
            "Precision: 0.4186335403726708\n",
            "Recall: 0.49558823529411766\n",
            "Weighted auc: 0.7392732524515159\n",
            "Auc: 0.7392732524515159\n",
            "Weighted acc: 0.7392732524515159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pRoGBWEwsE8r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Distance-based"
      ]
    },
    {
      "metadata": {
        "id": "TGnrY0JzrnbZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NdirSLbasIFR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Rule-based"
      ]
    },
    {
      "metadata": {
        "id": "gzb7iy-qrnW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fsaRhuz3sJ7p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Ensemble"
      ]
    },
    {
      "metadata": {
        "id": "KmLYxDGIrnV-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j-Pti0DQrnDi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}